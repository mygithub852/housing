{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hvplot.pandas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAhousing = pd.read_csv('')\n",
    "USAhousing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(USAhousing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAhousing.hvplot.hist(by='Price', subplots=False, width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAhousing.hvplot.hist(\"Price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAhousing.hvplot.scatter(x='Avg. Area House Age', y='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAhousing.hvplot.scatter(x='Avg. Area Income', y='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAhousing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(USAhousing.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = USAhousing[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n",
    "               'Avg. Area Number of Bedrooms', 'Area Population']]\n",
    "y = USAhousing['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val(model):\n",
    "    pred = cross_val_score(model, X, y, cv=10)\n",
    "    return pred.mean()\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    print('__________________________________')\n",
    "    \n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std_scalar', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression(normalize=True)\n",
    "lin_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the intercept\n",
    "print(lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'True Values': y_test, 'Predicted Values': pred}).hvplot.scatter(x='True Values', y='Predicted Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Error Values': (y_test - pred)}).hvplot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lin_reg.predict(X_test)\n",
    "train_pred = lin_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "model = RANSACRegressor(base_estimator=LinearRegression(), max_trials=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Robust Regression\", *evaluate(y_test, test_pred) , cross_val(RANSACRegressor())]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "Test set evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred) , cross_val(Ridge())]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0.1, \n",
    "              precompute=True, \n",
    "#               warm_start=True, \n",
    "              positive=True, \n",
    "              selection='random',\n",
    "              random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred) , cross_val(Lasso())]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Elastic Net Regression\", *evaluate(y_test, test_pred) , cross_val(ElasticNet())]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_2_d = poly_reg.fit_transform(X_train)\n",
    "X_test_2_d = poly_reg.transform(X_test)\n",
    "\n",
    "lin_reg = LinearRegression(normalize=True)\n",
    "lin_reg.fit(X_train_2_d,y_train)\n",
    "\n",
    "test_pred = lin_reg.predict(X_test_2_d)\n",
    "train_pred = lin_reg.predict(X_train_2_d)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Polynomail Regression\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = sgd_reg.predict(X_test)\n",
    "train_pred = sgd_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=Adam(0.00001), loss='mse')\n",
    "\n",
    "r = model.fit(X_train, y_train,\n",
    "              validation_data=(X_test,y_test),\n",
    "              batch_size=1,\n",
    "              epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'True Values': y_test, 'Predicted Values': pred}).hvplot.scatter(x='True Values', y='Predicted Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(r.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(r.history).hvplot.line(y=['loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Artficial Neural Network\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = rf_reg.predict(X_test)\n",
    "train_pred = rf_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Random Forest Regressor\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel='rbf', C=1000000, epsilon=0.001)\n",
    "svm_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = svm_reg.predict(X_test)\n",
    "train_pred = svm_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"SVM Regressor\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.set_index('Model', inplace=True)\n",
    "results_df['R2 Square'].plot(kind='barh', figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
